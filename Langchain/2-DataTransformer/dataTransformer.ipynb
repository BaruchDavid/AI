{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e5e3f9",
   "metadata": {},
   "source": [
    "RAG:\n",
    "\n",
    "- Retrieval → Abruf von externen Informationen (z. B. aus einer Datenbank, Dokumenten oder dem Web).\n",
    "- Augmented → Diese Informationen werden in den Generierungsprozess „eingespeist“ und erweitern das Modellwissen.\n",
    "- Generation → Das Sprachmodell erzeugt darauf basierend eine Antwort oder ein neues Dokument.\n",
    "\n",
    "In zweiten Schritt wird Augmented, also das Erzeugen von Chunks ausgeführt\n",
    "\n",
    "Man braucht dafür zumindest die Lib: langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf1aa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Neunter Awa, 3929 (68 unseres Zeitalters) Römer verbrennen Zweiten Tempel. Ein Drittel \n",
      "der Bevölkerung wurde ermordet oder als Sklaven verkauft. \n",
      "Johanan Ben Sakai: Oberkauft von Waisen nach der Zerstörung vom 2. Temepl \n",
      "Anführen der Schamai-Schule. Sohar schreibt, dass er Sod kannte. \n",
      "Nach der Zerstörung vom 2. Tempel gründete er Jeschiwa in Jawne. \n",
      " \n",
      "Joschua ben Naija, Schüler von Johanan Ben Zakai. Er hat Unkelus ausgebildet. \n",
      " \n",
      "Eliezer ben Orkanos, Schüler von Johanan ben Zaki. Sein Schüler war Unkelus und Rabi \n",
      "Akiwa. Er war nah zu der Schamai-Schule. Er wurde von der Gemeinde entfernt, weil er \n",
      "sich nicht nach der Mehrheit richtete. Nach dem Tod von Elizer ben Orkanos wurde er zu \n",
      "der Gemeinde wieder hinzugefügt und seine Gesetze werden angewandt. Er hat das \n",
      "Buch „Pirkei deabi Elizer“ geschrieben. \n",
      "Raban Gamliel: Verwandter vom König David. Er hat „Amida“ und „Pessah Seder „ \n",
      "herausgegeben. Er war Oberhaupt vom Sandhedrin. \n",
      " \n",
      "Hania ben Dosa: Hat viele Wunder vollbracht, Leute geheilt. \n",
      " \n",
      "Nehunja ben Akana wandte die Methodgebet  „Klalej Ufratej“ bei Toralernen an. Hat \n",
      "Gesetze festgelegt. Hat das Schabat-Schaharit und Ana-Benoah geschrieben. Dieses \n",
      "Gebet hat 42 Wörter, jeder nfangsbuchstabe ist Teil von G’tt Namen aus 42 Buchen.  \n",
      " \n",
      "Rabi Akiva: Vorherige Waisen waren seine Lehrer. Er konnte die Kronen „Koron“ über den \n",
      "Buchstaben der Wörter in der Tora interpritieren. Er verstand die Korrelation zwischen \n",
      "dem freien Willen und dass G’tt alles vorherbestimmt. Er hatte viele Schüler, einige von \n",
      "denen schrieben die Michna.' metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-12-09T11:49:09+01:00', 'author': 'Roma Kap', 'moddate': '2025-12-09T11:49:09+01:00', 'source': '../1-DataIgnestion/Tempel.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "## load pdf \n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdfLoader = PyPDFLoader('../1-DataIgnestion/Tempel.pdf')\n",
    "pdfFile = pdfLoader.load()\n",
    "print(pdfFile[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df389774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Neunter Awa, 3929 (68 unseres Zeitalters) Römer'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## splitte 'Documents' rekursiv Buchstabe für Buchstabe\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=50, chunk_overlap=5)\n",
    "## hier hat man schon den Text als \"Document\"\n",
    "print(type(pdfFile[0]))\n",
    "final_documents = text_splitter.split_documents(pdfFile) ##splitte Documents\n",
    "final_documents[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13bc957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "page_content='Beispiel: Alltag am'\n",
      "page_content='am Donnerstag'\n",
      "page_content='(A2-Niveau,'\n"
     ]
    }
   ],
   "source": [
    "## Nehme Text und erzeuge Chunks von Typ 'Document'ArithmeticError\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open(\"../1-DataIgnestion/HKurs.txt\") as text:\n",
    "    content = text.read() ## hier hast man nur text, keinen 'Document' Type\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(chunk_size=20, chunk_overlap=10)\n",
    "documents = recursive_text_splitter.create_documents([content])\n",
    "print(type(documents[0]))\n",
    "print(documents[0]) ##man sieht eine Überlappung hier \n",
    "print(documents[1]) ##und hier \n",
    "print(documents[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "462bf32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 604, which is longer than the specified 20\n",
      "Created a chunk of size 360, which is longer than the specified 20\n",
      "Created a chunk of size 146, which is longer than the specified 20\n",
      "Created a chunk of size 181, which is longer than the specified 20\n",
      "Created a chunk of size 97, which is longer than the specified 20\n",
      "Created a chunk of size 184, which is longer than the specified 20\n",
      "Created a chunk of size 151, which is longer than the specified 20\n",
      "Created a chunk of size 138, which is longer than the specified 20\n",
      "Created a chunk of size 85, which is longer than the specified 20\n",
      "Created a chunk of size 69, which is longer than the specified 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "INHALT_0: \n",
      " page_content='Beispiel: Alltag am Donnerstag (A2-Niveau, männliche Person)\n",
      "Morgens\n",
      "- Am Donnerstag stehe ich um sieben Uhr auf.\n",
      "- Ich wasche mich und ziehe mich an.\n",
      "- Dann frühstücke ich: Brot mit Käse und ein Glas Saft.\n",
      "- Um acht Uhr gehe ich zur Arbeit / zur Uni.\n",
      "Mittags\n",
      "- Mittags esse ich in der Kantine oder zu Hause.\n",
      "- Ich mag Suppe und Salat.\n",
      "- Nach dem Essen mache ich eine kleine Pause.\n",
      "- Um ein Uhr arbeite ich weiter.\n",
      "Abends\n",
      "- Am Abend komme ich um sechs Uhr nach Hause.\n",
      "- Ich koche das Abendessen, zum Beispiel Nudeln mit Gemüse.\n",
      "- Danach sehe ich fern oder lese ein Buch.\n",
      "- Um zehn Uhr gehe ich ins Bett.'\n",
      "INHALT_1: \n",
      " page_content='Übungsidee\n",
      "- Versuche, die Sätze laut nachzusprechen.\n",
      "- Danach kannst du kleine Änderungen machen: z. B. „Ich stehe um acht Uhr auf“ oder „Ich esse Pizza am Abend“.\n",
      "- So übst du, über deinen eigenen Alltag zu sprechen.\n",
      "Willst du, dass ich dir gleich ein Mini-Rollenspiel vorbereite, wo du mir deinen Donnerstag erzählst und ich dir einfache Fragen dazu stelle?'\n",
      "INHALT_2: \n",
      " page_content='Morgens – Alltag am Donnerstag (Hebräisch mit Umschrift)\n",
      "- Am Donnerstag stehe ich um sieben Uhr auf.\n",
      " Beyom ha‑shlishi ani mitorer be‑sheva sha‘a'\n"
     ]
    }
   ],
   "source": [
    "## man kann auch mit einem einfachen CharacterTextSplitter arbeiten:\n",
    "\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\"\\n\\n\", chunk_size=20, chunk_overlap=4)\n",
    "documents = text_splitter.create_documents([content])\n",
    "## dieser Splitter sagt z.b Created a chunk of size 604, which is longer than the specified 20\n",
    "## weil er den Seperator \"\\n\\n\" nicht findet\n",
    "print(type(documents[0]))\n",
    "print(f\"INHALT_0: \\n {documents[0]}\") ##man sieht eine Überlappung hier \n",
    "print(f\"INHALT_1: \\n {documents[1]}\") ##und hier \n",
    "print(f\"INHALT_2: \\n {documents[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec423883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "Willkommen auf meiner Beispielseite\n",
      "Abschnitt 1  \n",
      "Abschnitt 2\n"
     ]
    }
   ],
   "source": [
    "## dieser Splitter unterstütz nur h1,h2,h3 usw... tags\n",
    "\n",
    "from langchain_text_splitters import HTMLHeaderTextSplitter\n",
    "\n",
    "html_string = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "<html lang=\"de\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\" />\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
    "    <title>Beispiel HTML Dokument</title>\n",
    "</head>\n",
    "<body>\n",
    "    <header>\n",
    "        <h1>Willkommen auf meiner Beispielseite</h1>\n",
    "        <nav>\n",
    "            <ul>\n",
    "                <li><a href=\"#section1\">Abschnitt 1</a></li>\n",
    "                <li><a href=\"#section2\">Abschnitt 2</a></li>\n",
    "            </ul>\n",
    "        </nav>\n",
    "    </header>\n",
    "\n",
    "    <main>\n",
    "        <section id=\"section1\">\n",
    "            <h2>Abschnitt 1</h2>\n",
    "            <div>\n",
    "                <p>Dies ist ein Beispieltext in einem <strong>Paragraph</strong>. <br />\n",
    "                Hier wird ein Zeilenumbruch demonstriert.</p>\n",
    "            </div>\n",
    "        </section>\n",
    "\n",
    "        <section id=\"section2\">\n",
    "            <h2>Abschnitt 2</h2>\n",
    "            <article>\n",
    "                <p>Ein weiterer Absatz mit einem <em>kursiven</em> Text und einem Link: \n",
    "                <a href=\"https://example.com\">Beispielseite</a>.</p>\n",
    "                <ul>\n",
    "                    <li>Listenpunkt 1</li>\n",
    "                    <li>Listenpunkt 2</li>\n",
    "                </ul>\n",
    "            </article>\n",
    "        </section>\n",
    "    </main>\n",
    "\n",
    "    <footer>\n",
    "        <small>&copy; 2025 Beispielseite</small>\n",
    "    </footer>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "## list with tuple\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"header1\"),\n",
    "    (\"h2\", \"header2\"),\n",
    "    (\"h3\", \"header3\")\n",
    "]\n",
    "\n",
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on)\n",
    "splitted_html_text = html_splitter.split_text(html_string)\n",
    "\n",
    "print(type(splitted_html_text[0])) ## In der Liste sind die benötigten Dokumente\n",
    "print(splitted_html_text[0].page_content)\n",
    "print(splitted_html_text[1].page_content)\n",
    "\n",
    "html_splitter.split_text_from_url(\"www.zdf.de\") ##man kann auch eine url übergeben und dessen html nach h-tags splitten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6de6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n",
      "div-splitter: {'header2': 'Dies ist Abschnitt 1 mit etwas Text.'}\n",
      "Dies ist Abschnitt 1 mit etwas Text.\n",
      "div-splitter: {'header2': 'Abschnitt 2 enthält eine Liste:\\n\\nEintrag A\\nEintrag B'}\n",
      "Abschnitt 2 enthält eine Liste: \n",
      " \n",
      " Eintrag A \n",
      " Eintrag B\n",
      "div-splitter: {'header2': 'Footer-Bereich ohne Überschriften.'}\n",
      "Footer-Bereich ohne Überschriften.\n"
     ]
    }
   ],
   "source": [
    "## Dieser Splitter unterstützt beliebige Tags\n",
    "\n",
    "from langchain_text_splitters import HTMLSectionSplitter\n",
    "\n",
    "html_without_h_tags=\"\"\"\n",
    "\n",
    "<!doctype html>\n",
    "<html>\n",
    "  <body>\n",
    "    <div class=\"section\">\n",
    "      <p>Dies ist Abschnitt 1 mit etwas Text.</p>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"section\">\n",
    "      <p>Abschnitt 2 enthält eine Liste:</p>\n",
    "      <ul>\n",
    "        <li>Eintrag A</li>\n",
    "        <li>Eintrag B</li>\n",
    "      </ul>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"footer\">\n",
    "      <p>Footer-Bereich ohne Überschriften.</p>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "## man muss zwingend mind. einen h-tag übergeben \n",
    "## aber wenn man einen html-dokument ohne h-tags hat, wird es nach dem nächsten splitter\n",
    "## gechunkt, und das ist der div-tag in diesem Beispiel\n",
    "headers_to_split_on = [\n",
    "    (\"h1\", \"header1\"),\n",
    "    (\"div\", \"header2\")\n",
    "]\n",
    "\n",
    "html_splitter = HTMLSectionSplitter(headers_to_split_on)\n",
    "chunked_html_text = html_splitter.split_text(html_without_h_tags)\n",
    "print(type(chunked_html_text[0])) ## In der Liste sind die benötigten Dokumente\n",
    "for document in chunked_html_text:\n",
    "\n",
    "    print(f\"div-splitter: {document.metadata}\")\n",
    "    print(document.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitte JSON\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "\n",
    "json_data = requests.get(\"https://api.smith.langchain.com/openapi.json\").json()\n",
    "json_splitter = RecursiveJsonSplitter(max_chunk_size = 300)\n",
    "json_chunks = json_splitter.split_json(json_data)\n",
    "\n",
    "for chunk in json_chunks[:3]:\n",
    "    print(chunk)\n",
    "\n",
    "## create Dokuments from json\n",
    "\n",
    "chunked_docs = RecursiveJsonSplitter.create_documents(texts=[json_data])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
